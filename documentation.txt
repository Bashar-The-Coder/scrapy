Today we crawl books to scrape page

1. to see all available genspider commands
scrapy genspider -l # l for list

2. to create crawlspider
scrapy genspider -t crawl books_crawl x # here -t for template and crawl for crawl spider if we dont declare crawl scrapy generate simple spider for us
code .

# rules attribute are tuple
    #linkextractors as le
    # it will extract all the link and it only allow the links that contain this particular item and ignore rest all the item
    
3. to crawl any website we inspect the link 

to run crawler inside the directory
scrapy crawl books_crawl